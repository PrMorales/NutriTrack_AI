import streamlit as st
import os
import google.generativeai as genai
from google.generativeai import types
import pandas as pd
import datetime

# --- CONFIGURA칂츾O DE IA (LEITURA ROBUSTA) ---
try:
    chave_secreta = os.environ.get("GEMINI_API_KEY") 

    if not chave_secreta:
        st.error("Erro de Configura칞칚o: Chave GEMINI_API_KEY ausente.")
        st.stop()
        
    client = genai.Client(api_key=chave_secreta)
    
except Exception as e:
    st.error(f"Falha na Inicializa칞칚o da API: {e}")
    st.stop()
    
# --- CONFIGURA칂츾O INICIAL DA P츼GINA ---
st.set_page_config(page_title="NutriTrack IA - Vegetariano", layout="wide")

# Estilo para UI limpa
st.markdown("""
    <style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    .st-emotion-cache-1r6r8qj {max-width: 800px;}
    </style>
    """, unsafe_allow_html=True)

st.title("游꺔 NutriTrack IA: An치lise Vegetariana Inteligente")
st.subheader("Informe sua refei칞칚o e receba a an치lise e dicas!")

# Inicializa o hist칩rico do chat
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "model", "content": "Ol치! Eu sou seu assistente NutriTrack IA. Diga-me o que comeu para receber a an치lise nutricional e dicas vegetarianas."}
    ]

# --- FUN칂츾O DE CONVERSA COM A IA ---
def conversar_com_ia(prompt):
    
    # INSTRU칂츾O DETALHADA PARA FOR칂AR A SA칈DA EM TABELA E DAR DICAS VEGETARIANAS
    system_instruction = (
        "Voc칡 칠 o NutriTrack AI, um especialista em nutri칞칚o focado em dietas vegetarianas. "
        "1. Analise o alimento ou refei칞칚o fornecida pelo usu치rio. "
        "2. Retorne uma tabela formatada em MARKDOWN com 7 colunas (Calorias, A칞칰car, Vitamina C, Prote칤na, Ferro, Carboidratos, Gorduras). Use valores estimados e unidades. "
        "3. Sempre adicione uma breve dica de alimenta칞칚o focada em vegetarianos, especialmente sobre como obter nutrientes como Ferro e Prote칤na."
        "4. Mantenha um tom profissional."
    )
    
    # 1. Adiciona a instru칞칚o do sistema
    contents_to_send = [
        types.Content(
            role="user",
            parts=[types.Part.from_text(system_instruction)]
        )
    ]
    
    # 2. Adiciona a mensagem atual do usu치rio
    contents_to_send.append(
        types.Content(role="user", parts=[types.Part.from_text(prompt)])
    )

    # Chama a API do Gemini
    response = client.models.generate_content_stream(
        model='gemini-2.5-flash',
        contents=contents_to_send
    )
    return response

# ----------------------------------------------------
# INTERFACE PRINCIPAL: CHATBOT
# ----------------------------------------------------

# Exibir hist칩rico de mensagens
for message in st.session_state.messages:
    # Mapeia a role 'model' (Gemini) para 'assistant' (Streamlit)
    role = "assistant" if message["role"] == "model" else "user" 
    with st.chat_message(role):
        st.markdown(message["content"])

# Capturar novo input do usu치rio
if prompt := st.chat_input("Ex: 'Sandu칤che de pasta de amendoim com banana'"):
    
    # 1. Exibir input do usu치rio
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 2. Gerar e exibir resposta da IA (streaming)
    with st.chat_message("assistant"):
        with st.spinner("Analisando refei칞칚o e gerando tabela nutricional..."):
            try:
                response_stream = conversar_com_ia(prompt)
                full_response = st.write_stream(response_stream)
            except Exception as e:
                # Exibe o erro amig치vel
                st.error("Erro na comunica칞칚o com a IA. Tente novamente ou verifique sua chave GEMINI_API_KEY.")
                full_response = "Erro de API." 
        
    # 3. Adicionar resposta completa ao hist칩rico
    st.session_state.messages.append({"role": "model", "content": full_response})